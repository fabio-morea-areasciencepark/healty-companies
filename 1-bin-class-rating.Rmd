--- 
title: "Excercise: binary classification "
author: "Fabio Morea"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Business case

<!-- The goal is not "build a ML system on this data", but rather a question to be answered. -->
<!-- So we should: -->

<!-- 0. understand the question (that probably includes giving an interpretation to "hardest") -->
<!-- 1. design a method for answering the question -->
<!-- 2. implement that method -->
<!-- 3. provide the answer by applying the method -->

*Business case for this excercise* 
RCM is the regional association of composite material processing companies, that counts over 1000 associates (companies that have their head office or a local unit in Friuli Venezia Giulia and are interested in some way in manufacturing with composite materials).  RCM is monitoring the performance of its members: each company with a performance level (Top/Mid/Low) that is used for further activities (e.g. Top performers are featured in the newsletter, Mid and Low performers receive different proposals…).
The classification algorithm is based on financial ratings issued by Modefinance (purchased at 5,00€ per company). Rating is expressed as a value 1 to 10 and 
The performance level is now based on ModeFinance rating: 

* Top: rating 7 to 10
* Mid: rating 5-6
* Low: rating 1 to 4

**Objective:** RCM  wants to develop a new method, leading to the same classification, replacing financial ratings with balance sheet data (which can be purchased at a significantly lower cost, € 0.75 per company).
The expected result is a model (learning and prediction modules) and a detailed report describilng the model performance (error rate, robustness to unbalanced data, ...) 

**Constraints: ** training and classification will be performed on a laptop, twice a year. No specific constraints on time or computation effort (even if it takes hours, it’s ok).

**Workflow**
- insert picture here
-	Classification tree

## Understanding the data
TODO insert figure here

Data is available from 2 sourecs: 
* cmp.csv
* bsd.csv
* rating.csv

and sould be pre-processed to obtain two vectors: X and y.


This section is dedicated to load and preprocess financial statement data for the dataset *imprese-fvg*. 
The relevant file is "_DATA/imprese-fvg/bilanci-fvg.csv".

```{r include=FALSE}
library(tidyverse)
library(ggpubr)
library(ggthemes)
theme_set( theme_gray(base_size = 12))  
```
 
 
 
## Financial data 
The relevant files are

* *cmp.csv*

* *bsd.csv*. Each observation is a summary of balance sheet data (bsd) of a company (identified by *cf*) for a given year. Column labels need some improvement to remove whitespaces and possibly short english names.

* *rating.csv*
 

```{r}
pathTidyData = './../../_data/tidy/'
companies <-  read_csv( paste0(pathTidyData,"cmp.csv") ) 
bsd <-        read_csv( paste0(pathTidyData,"bsd.csv") ) 
rating <-     read_csv( paste0(pathTidyData,"rating.csv") ) 
codes <-      read_csv( paste0(pathTidyData,"nace.csv") )

```

## Selection of sample

Select NACE code (see _data/ino/ for a complete list of codes https://ec.europa.eu/eurostat/web/products-manuals-and-guidelines/-/ks-ra-07-015
codes are organized by: Division / Group / Class

We are interested in Division 22
22 Manufacture of rubber and plastic products 
22.1 Manufacture of rubber products 
22.11 Manufacture of rubber tyres and tubes; retreading and rebuilding of rubber tyres 2211 
22.19 Manufacture of other rubber products 2219 
22.2 Manufacture of plastics products 
22.21 Manufacture of plastic plates, sheets, tubes and profiles 2220* 
22.22 Manufacture of plastic packinggoods 2220* 
22.23 Manufacture of builders’ ware of plastic 2220* 
22.29 Manufacture of other plastic products 

And only companies that have a duty of disclosure of financial information. 
SOCIETA' DI CAPITALE|SU|SOCIETA' A RESPONSABILITA' LIMITATA CON UNICO SOCIO
SOCIETA' DI CAPITALE|SR|SOCIETA' A RESPONSABILITA' LIMITATA
SOCIETA' DI CAPITALE|SP|SOCIETA' PER AZIONI
SOCIETA' DI CAPITALE|SD|SOCIETA' EUROPEA
SOCIETA' DI CAPITALE|RS|SOCIETA' A RESPONSABILITA' LIMITATA SEMPLIFICATA
SOCIETA' DI CAPITALE|RR|SOCIETA' A RESPONSABILITA' LIMITATA A CAPITALE RIDOTTO
SOCIETA' DI CAPITALE|AU|SOCIETA'  PER AZIONI CON SOCIO UNICO
SOCIETA' DI CAPITALE|AA|SOCIETA' IN ACCOMANDITA PER AZIONI

```{r}
#select only some types of ng2 (natura giuridica)
selectedNg = c("SU", "SR", "SP", "SD", "RS", "RR", "AU", "AA")
companies <- companies %>% filter(ng2 %in% selectedNg)
#select only division 28 
selectedCf <- codes %>% filter(division == 28) %>% select(cf)
companies  <- companies %>% semi_join(selectedCf) #semi_join() return all rows from x with a match in y
bsd        <- bsd       %>% semi_join(selectedCf)
rating     <- rating    %>% semi_join(selectedCf)
checkDuplicates <- companies %>% filter(duplicated(.[["cf"]]))#check duplicates (none expected)
```

Now we have a sample of {r length(companies)} companies. Duplicates are {r length(checkDuplicates)}.




## Financial Ratings

Financial ratings issued by ModeFinance https://www.modefinance.com/it
TODO: improve description: 
> The credit rating and commercial credit limit available within the s-peek application are evaluated through an innovative methodology called Multi Objective Rating Evaluation which is owned by modeFinance. This innovative methodology studies a corporation as a complex system and deepens the analysis on its different aspects: solvency, debt coverage, liquidity, cash conversion cycle, profitability, fixed asset coverage, compared with the sector which it belongs to and so on.
With effect from July 10th, 2015, modeFinance Srl is registered as a credit rating agency in accordance with Regulation (EC) No 1060/2009 of the European Parliament ad of the Council of 16 September 2009 (the Credit Rating Agencies Regulation link). MORE Methodology is used by modeFinance also as part of the process of issuance of Credit Ratings in compliance with Regulation (EC) No 1060/2009 of the European Parliament ad of the Council of 16 September 2009 (the Credit Rating Agencies Regulation).

## create X and y 

```{r}
bsd <- bsd %>% filter(year == 2019)
rating <- rating %>%  filter(year == 2019)

tmp <- companies %>% 
        inner_join(bsd, by = "cf") %>% 
        inner_join(rating, by = "cf") 
     
checkDuplicates <- tmp %>% filter(duplicated(.[["cf"]]))#check duplicates (none expected)

names <- tmp %>% select(name,cf,idCompany)
X     <- tmp %>% select(idCompany, is.sme, is.startup, is.fem, is.young, is.fore, yearsInBusiness, totAssets, totIntang,accounts,totEquity,debts,prod,revenues,personnel,valCost, ammort, profLoss, valAdded, deprec, noi)

y     <- tmp %>% 
          mutate(isHealthy = rating010 >= 7)  %>% 
  #        mutate(isHealthy = ifelse(rating010 >= 7,"Y","N"))  %>% 
          select(idCompany,isHealthy)
```

Create a label - at the current stage a binary label is enough to test out method

```{r}

data <- X %>% 
       inner_join(y)%>% 
        select(-idCompany)%>%
        mutate(isHealthy = as.factor(isHealthy)) 

```

## select most relevant features, based on domain knowledge

we start with a few atttributes, that are deemed more relevant
included:
- totAssess = totale attivo = total assets
- noi  = (ron) reddito operativo netto =  (noi) net operating income
- personnel = totale costi del personale = total personnel costs
- debts = debiti esigibili entro l'esercizio successivo = debts due within the following financial year

not included:

- totEquity = totale patrimonio netto = total equity
- profLoss = uile/perdita esercizio ultimi = profit / loss for the last financial year
- accounts = crediti esigibili entro l'esercizio successivo = accounts receivables
- totIntang = totale immobilizzazioni immateriali = total intangible fixed assets
- prod = totale valore della produzione = total production value
- revenues = ricavi delle vendite = revenues from sales
- valCost = differenza tra valore e costi della produzione = difference between production value and production costs
- ammort = ammortamento immobilizzazione immateriali = amortisation
- valAdded = valore aggiunto = value added
- deprec = tot.aam.acc.svalutazioni = total amortisation, depreciation and write-downs


```{r}


data <- data %>% select(totAssets,noi,personnel, debts,deprec, isHealthy) %>%
            mutate(relNoi =        noi/totAssets) %>%
            mutate(relPers =       personnel/totAssets) %>%
            mutate(relDebts =      debts/totAssets) %>%
            mutate(relDeprec =    deprec/totAssets)%>%
            select(-totAssets,-noi,-personnel,-debts, -deprec)
```

We create normalized variables `{r names(data)}`   


## visualize data

Question: a general overview of the dataset
Design: pairs plot = matrix of scatterplots that lets you understand the pairwise relationship between different variables in a dataset

Questions: are the variable of the same order of magnitude?

```{r}
ggplot(stack(data), aes(x = ind, y = values)) +
 stat_boxplot(geom = "errorbar", width = 0.5) +
 labs(x="Samples", y="Frequency") +
 geom_boxplot(fill = "white", colour = "#3366FF") + coord_flip()

```
Questions: are the variables 

```{r}
data %>% pivot_longer(cols=!isHealthy) %>% ggplot(aes(x=isHealthy, y=value, color = isHealthy)) + geom_boxplot() + facet_grid(.~name, scales="free") 

# require(GGally)
# data %>%  ggpairs()

#plot(data)

```



Visualize differences between Healty and non healty companies according to two variables

```{r}
plot1 <- data %>% ggplot(aes(x=relNoi, y=relDebts,  color=isHealthy)) + geom_point()
plot2 <- data %>% ggplot(aes(x=relDeprec, y=relPers, color=isHealthy)) + geom_point()
ggarrange(plot1,plot2)

 
```
the figure above higlights shows at a glance that is no trivial decision boundary. 


Question: Are the distribution of variables different between Healty and non-healty companies?
Design: three boxplots
```{r}
data %>% pivot_longer(cols=!isHealthy) %>% ggplot(aes(x=isHealthy, y=value,  color=isHealthy)) + geom_boxplot() + facet_grid(.~name, scales="free")  
data %>% pivot_longer(cols=!isHealthy) %>% ggplot(aes(x=isHealthy, y=value,  color=isHealthy)) + geom_violin() + facet_grid(.~name, scales="free")  

```

we can see small differences.

Conclusions
- Healty and non healty  appear hard to tell apart with the given attributes
- Which attributes appear more useful for inferring health? relDebts and relNoi


## Tree 
[short intro to tree learning]
We use "tree" that provides:
- a function for doing the learning `tree()`
- a function for doing the prediction, usually named `predict()`

The learning function in tree requires a dataframe and an indication of the dependency, using a data type, peculiar of R, known as **formula** as in the examples `a ~ b+c` (variable `a` depends on `b` and `c`) or `a ~ .` (variable `a`  depends on all the other variables).

```{r}
require(tree)
model <- tree(isHealthy~.,data) #~relNoi+relDebts
plot(model)
text(model)
print(model)
```
the printed tree shows that "yearsInBusiness is not used"
or with another library

```{r}
# require("rpart")
# require("rpart.plot")
# model = rpart(isHealthy ~ . , 
#             data = train_data, 
#             method = "class" , 
#             minsplit = 1, 
#             minbucket = 1, 
#             cp = -1)
# 
# rpart.plot(model)
# 
# predictions = predict(model, train_data)
# 
# table(predictions)
# 
# print(model)

```
## measure the error
We have a few options:

- measure error on the learning data
- measure error on test data statically left out (e.g., 20% of the overall data)
- measure error with a k-fold CV
- measure error with a **leave-one-out** CV (LOOCV), i.e., a k-fold CV with $k=n$, $n$ being the number of observations in the available data

### measure error on the learning data
It's an easy option but we know that, when $k_\text{min}=1$, the error on the learning data is 0 by definition.
It would hence pointless to compare a set of 0s...
We need to ascertain which is the default value of $k_\text{min}$ in `tree()`, that requires to consume the documentation: [I leave this for your enjoiment.[TODO]

# measure error on test data
split  (e.g., 20% of the overall data)
 We use `sample()` for shuffling the set of row-indexes of `d` and take a subset of this set that will act as the indexes of the learning data.
```{r}
fraction <- .8
indexes.learning = sample(c(1:nrow(data)))[1:(nrow(data)*fraction)]
# idxs <- sample(nrow(d), n*fraction)
# train_data <- df[ idxs,]
# test_data  <- df[-idxs,]
```

Now we can learn the tree  
```{r}
model = tree(isHealthy~., data[indexes.learning,])
plot(model)
text(model)
```

The `predict()` function takes a dataframe with possibly new observations and predict the corresponding labels: the results is hence a vector.
```{r}
predicted.health = predict(model, data[-indexes.learning,], type = "class")
```
Note that:

- the `-` preceding `indexes.learning` means "select all but those"
- `type="class"` is needed to obtain a vector of factors, rather than a more complex thing: see the documentation of `predict.tree()`
- `predict()` doesn't cheat: even if `d[-indexes.learning,]` actually contains also the correct $y$ value, it is not using it

Now we can compute the classification error rate by comparing `predicted.y` against the expected $y$:
```{r}
classification.error <- length(which(predicted.health!=data$isHealty[-indexes.learning]))/length(predicted.health)
classification.error

errors <- data[-indexes.learning,] %>% 
  select(isHealthy) %>% 
  mutate(ph = predicted.health) %>%
  mutate(err = (isHealthy = ph)) %>% 
  filter(err == TRUE) %>% 
  nrow()
print(errors)
```

Note that `which()` returns the indexes of a boolean vector items that are true.

Another way is to "compute" the **confusion matrix** and then obtaining the error from that.
The confusion matrix shows the number misclassifications, class by class:
```{r}
table(predicted.health, data$isHealthy[-indexes.learning])
```
Given that matrix, the accuracy of classification is:
```{r}
conf.matrix = table(predicted.health, data$isHealthy[-indexes.learning])
sum(diag(conf.matrix))/sum(conf.matrix)
```
and the error rate can be computed as:
```{r}
error = 1-sum(diag(conf.matrix))/sum(conf.matrix)
error
```

Out of simplicity, we might build a function that does all those operations together, with some parameters:
```{r}
computeErrorRate = function(categorical.y.name, data, learner, p.learn = 0.8, ...) {
  indexes.learning = sample(c(1:nrow(data)))[1:(nrow(data)*p.learn)]
  model = learner(formula(paste0(categorical.y.name,"~.")), data[indexes.learning,], ...)
  predicted.y = predict(model, data[-indexes.learning, ], type="class")
  #length(which(predicted.y!=data[-indexes.learning, categorical.y.name]))/length(predicted.y)
  
  
  errors <- data[-indexes.learning,] %>% 
    select(categorical.y.name) %>% 
    mutate(ph = predicted.y) %>%
    mutate(err = (categorical.y.name = ph)) %>% 
    filter(err == TRUE) %>% 
    nrow()
  
  errors/length(predicted.y)

}


print(computeErrorRate("isHealthy", data, tree))
print(computeErrorRate("isHealthy", data, rpart))

```



## Train a single unproned tree


## check overfitting


## estimate error

## optimized model 


## Predict


## Conclusions
